{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "class ScaledAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self):\n",
    "        super(ScaledAttention, self).__init__()\n",
    "\n",
    "    def call(self, query, key, value, mask=None):\n",
    "        # Calculate scaled dot-product attention\n",
    "        matmul_qk = tf.matmul(query, key, transpose_b=True)\n",
    "        scale = tf.cast(tf.shape(key)[-1], tf.float32)\n",
    "        scaled_attention_logits = matmul_qk / tf.math.sqrt(scale)\n",
    "\n",
    "        # Apply mask if provided\n",
    "        if mask is not None:\n",
    "            scaled_attention_logits += (mask * -1e9)\n",
    "\n",
    "        # Softmax to get attention weights\n",
    "        attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)\n",
    "        context_vector = tf.matmul(attention_weights, value)\n",
    "\n",
    "        return context_vector, attention_weights\n",
    "\n",
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_heads, d_model):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.d_model = d_model\n",
    "        assert d_model % self.num_heads == 0\n",
    "        self.depth = d_model // self.num_heads\n",
    "\n",
    "        self.wq = tf.keras.layers.Dense(d_model)\n",
    "        self.wk = tf.keras.layers.Dense(d_model)\n",
    "        self.wv = tf.keras.layers.Dense(d_model)\n",
    "\n",
    "        self.attention = ScaledAttention()\n",
    "        self.dense = tf.keras.layers.Dense(d_model)\n",
    "\n",
    "    def split_heads(self, x, batch_size):\n",
    "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n",
    "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
    "\n",
    "    def call(self, query, key, value, mask=None):\n",
    "        batch_size = tf.shape(query)[0]\n",
    "\n",
    "        query = self.wq(query)\n",
    "        key = self.wk(key)\n",
    "        value = self.wv(value)\n",
    "\n",
    "        query = self.split_heads(query, batch_size)\n",
    "        key = self.split_heads(key, batch_size)\n",
    "        value = self.split_heads(value, batch_size)\n",
    "\n",
    "        scaled_attention, attention_weights = self.attention(query, key, value, mask)\n",
    "        scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n",
    "        concat_attention = tf.reshape(scaled_attention, (batch_size, -1, self.d_model))\n",
    "        output = self.dense(concat_attention)\n",
    "\n",
    "        return output, attention_weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_heads = 8\n",
    "d_model = 64 \n",
    "batch_size = 2\n",
    "seq_len = 5\n",
    "\n",
    "query = tf.random.normal((batch_size , seq_len , d_model))\n",
    "key = tf.random.normal((batch_size , seq_len , d_model))\n",
    "value = tf.random.normal((batch_size , seq_len , d_model))\n",
    "\n",
    "mha = MultiHeadAttention(num_heads= num_heads , d_model=d_model)\n",
    "\n",
    "context_vector , attention_weights = mha(query , key , value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([2, 5, 64]), TensorShape([2, 8, 5, 5]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_vector.shape , attention_weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context vector:  tf.Tensor(\n",
      "[[[ 1.17092955e+00  1.74959034e-01  8.14614236e-01  2.72841901e-01\n",
      "    1.34353900e+00 -1.30290017e-01  5.54659963e-01 -1.54419971e+00\n",
      "   -3.62821728e-01 -5.39235994e-02  2.17677712e-01 -3.49965960e-01\n",
      "   -7.07851112e-01  2.61607729e-02 -6.27807736e-01 -4.51061606e-01\n",
      "   -6.79228753e-02  2.77737081e-01 -8.42350185e-01  8.42121243e-01\n",
      "    7.87424743e-01  7.60869265e-01 -7.86327124e-01  5.84989846e-01\n",
      "   -1.35983229e+00 -4.33838546e-01 -1.49074733e-01 -5.51107466e-01\n",
      "   -6.89930081e-01  2.37578437e-01 -1.07542656e-01 -1.31057358e+00\n",
      "   -6.41678870e-01 -2.73314446e-01 -5.26086152e-01  1.76131446e-02\n",
      "   -2.85808176e-01  6.76846355e-02 -1.13950111e-01  1.12478115e-01\n",
      "    1.91762790e-01 -3.83961618e-01 -1.15867168e-01 -4.52213645e-01\n",
      "   -2.61492521e-01 -3.65843594e-01  4.58277971e-01 -6.46082610e-02\n",
      "    9.02185380e-01  2.70749420e-01 -7.25422811e-04 -1.07466352e+00\n",
      "   -4.62511659e-01  3.71136725e-01 -3.28190923e-02 -8.58771086e-01\n",
      "    1.54520556e-01 -4.25858855e-01  3.79764885e-01  1.36500311e+00\n",
      "   -3.40535194e-01  4.83245105e-02 -2.52992418e-02  7.81548470e-02]\n",
      "  [ 4.71638918e-01 -3.87565464e-01  6.73222065e-01  2.98397560e-02\n",
      "    1.17432785e+00 -4.28047657e-01  2.83167809e-01 -1.08481050e+00\n",
      "   -5.46756387e-01  5.17562628e-01  5.71444295e-02  1.07156491e+00\n",
      "   -3.66794854e-01  2.90957272e-01 -7.12594986e-01 -8.65222067e-02\n",
      "    1.26717882e-02 -2.92329490e-01 -4.63692725e-01  4.07370418e-01\n",
      "    8.74332711e-02  5.72758675e-01 -1.08686352e+00  9.40672815e-01\n",
      "   -9.16541159e-01  5.28485715e-01  4.02854145e-01 -7.74127543e-01\n",
      "    1.68790311e-01  2.15558290e-01 -6.50647283e-01 -8.59944522e-01\n",
      "   -1.57791063e-01 -1.56956352e-02 -8.36796761e-02 -1.97958648e-01\n",
      "   -8.11550736e-01 -6.56717420e-02  1.95679963e-01  4.76023138e-01\n",
      "   -1.73576716e-02 -4.92867053e-01  2.12433651e-01 -2.60391086e-01\n",
      "   -3.77624720e-01 -1.24914300e+00  5.15348129e-02  3.44968617e-01\n",
      "    3.16776663e-01  3.32781762e-01  4.25039530e-01 -3.93374324e-01\n",
      "   -2.08430737e-01 -1.71030581e-01 -9.72969174e-01 -3.43767732e-01\n",
      "   -5.60089707e-01 -3.07199061e-01  5.74409068e-01  2.12071955e-01\n",
      "   -3.51680219e-01 -2.07118928e-01  9.30836797e-02 -1.79796472e-01]\n",
      "  [ 3.14461678e-01  1.69005379e-01  3.24995011e-01  5.85478723e-01\n",
      "    3.32640409e-01 -3.60140055e-01  5.88396430e-01 -5.97993731e-01\n",
      "    2.07757682e-01 -2.43490741e-01  6.19346201e-01  6.59238771e-02\n",
      "   -1.30136073e-01 -1.12119868e-01  2.18958268e-03  9.14685875e-02\n",
      "    5.13785958e-01  1.06396720e-01 -3.72800052e-01  5.26681483e-01\n",
      "    1.30199730e-01 -2.62585640e-01 -5.66814840e-01  8.16585541e-01\n",
      "   -1.11456180e+00 -2.59109169e-01  7.92439580e-01 -3.40939254e-01\n",
      "    4.08606604e-02  6.91069141e-02  1.20056979e-01 -1.06984520e+00\n",
      "   -8.18730518e-02  2.48345751e-02 -9.86787677e-02 -1.08646408e-01\n",
      "   -2.04882577e-01 -3.82929564e-01 -2.35712323e-02 -6.81308433e-02\n",
      "   -6.72522426e-01 -1.98649973e-01 -2.95670956e-01 -9.89185125e-02\n",
      "    3.70396376e-01 -5.57113826e-01 -1.39661208e-01  2.25866884e-01\n",
      "    5.41645050e-01 -4.29058186e-04 -3.90243046e-02 -6.81012450e-03\n",
      "    1.62275404e-01 -1.83821768e-01 -2.90413946e-01 -6.88269019e-01\n",
      "   -1.16232529e-01  4.22709882e-02  6.24590933e-01  1.38131648e-01\n",
      "    1.16790421e-01  3.51389945e-01 -2.54660964e-01 -2.82406747e-01]\n",
      "  [ 1.00816131e+00  1.38858110e-01  3.51273119e-01  8.82935345e-01\n",
      "    6.52097046e-01 -1.75491780e-01  5.22948265e-01 -5.53522527e-01\n",
      "   -4.91446972e-01 -2.60077715e-02 -7.22633600e-02 -1.89293325e-01\n",
      "   -5.63438773e-01 -1.36506841e-01 -3.58310521e-01 -3.37808400e-01\n",
      "    5.97906858e-03 -2.50493586e-01 -5.15444279e-01  4.59807843e-01\n",
      "    4.08952266e-01  3.36392641e-01 -3.80480051e-01  6.32908285e-01\n",
      "   -1.50184810e+00  2.28472631e-02  5.32169878e-01 -5.56752503e-01\n",
      "   -4.75418508e-01 -9.02665704e-02 -9.44744572e-02 -1.18928123e+00\n",
      "   -5.25190592e-01  1.48263752e-01 -2.30531603e-01 -1.30419910e-01\n",
      "    5.80727383e-02 -3.25823762e-03 -2.05996796e-01  2.96640933e-01\n",
      "   -8.90113562e-02 -4.18012857e-01  3.10950144e-03 -4.46185261e-01\n",
      "   -3.12608629e-01 -6.45300746e-01  1.94848508e-01 -1.95319555e-03\n",
      "    7.44115829e-01 -1.12343833e-01 -1.85787782e-01 -7.66431034e-01\n",
      "   -3.02806348e-01  4.68523681e-01  9.49647557e-03 -5.68630755e-01\n",
      "   -3.53462219e-01 -5.11023641e-01  2.10940108e-01  3.20778877e-01\n",
      "   -5.59861243e-01 -4.02262844e-02 -3.43782485e-01 -4.32511330e-01]\n",
      "  [ 7.60433376e-01  1.26808032e-01 -3.52711052e-01  1.43558115e-01\n",
      "    8.33793759e-01 -1.40179366e-01  5.77458322e-01 -1.13769460e+00\n",
      "   -1.91968530e-01  1.42246649e-01  1.94855109e-01  8.02358508e-01\n",
      "   -4.93560433e-01  1.28283650e-01 -1.74605563e-01  2.40700003e-02\n",
      "    2.53154874e-01 -3.66813302e-01 -9.51122880e-01  4.44288492e-01\n",
      "    9.77370590e-02  7.62358084e-02 -5.06151438e-01  2.73002505e-01\n",
      "   -9.45136547e-01 -7.24967197e-02  6.42632127e-01 -2.65375167e-01\n",
      "    1.45132914e-01  2.12130114e-01  1.59649670e-01 -1.27658558e+00\n",
      "   -6.18020952e-01 -4.99857396e-01  1.41664892e-01 -2.54307687e-01\n",
      "   -9.31028649e-03 -6.16785228e-01  2.10184529e-01 -2.83854276e-01\n",
      "   -4.14889216e-01 -1.01439118e-01 -4.63447385e-02 -4.92093623e-01\n",
      "   -1.60871848e-01 -7.93732822e-01  4.00468111e-01  6.93817794e-01\n",
      "    8.71452034e-01 -1.38215214e-01 -4.81179059e-01 -1.28378823e-01\n",
      "   -2.98282564e-01 -8.00963491e-02 -2.89049447e-02 -2.00684220e-01\n",
      "   -1.50205702e-01 -4.08864468e-01  3.02233517e-01  3.18273664e-01\n",
      "    1.00800181e-02  3.18316758e-01 -7.71346748e-01 -8.73624682e-01]]\n",
      "\n",
      " [[ 6.22548223e-01  1.88478325e-02 -1.17940292e-01  7.67591417e-01\n",
      "   -5.40381908e-01 -9.09195244e-01  2.82421201e-01 -6.36487246e-01\n",
      "    7.52320349e-01 -2.66543835e-01 -5.63986719e-01 -3.96862961e-02\n",
      "   -2.08071995e+00 -1.47154605e+00 -6.79726422e-01 -1.19585462e-01\n",
      "    1.36562562e+00  1.39201321e-02  1.70093405e+00 -2.50598699e-01\n",
      "   -6.16909385e-01  4.00506616e-01 -4.32876915e-01  5.70510812e-02\n",
      "    4.42620039e-01  8.16074133e-01 -2.73766637e-01  6.09452665e-01\n",
      "   -3.04896533e-01  1.46379447e+00 -2.90619791e-01 -9.63782966e-01\n",
      "   -3.96308690e-01 -2.29943424e-01  2.13721506e-02 -1.72958717e-01\n",
      "   -4.30614024e-01 -2.44740427e-01  8.43245924e-01  5.65265641e-02\n",
      "    1.42472699e-01 -9.53836203e-01 -2.12925419e-01 -7.78528631e-01\n",
      "   -7.64086425e-01 -1.00601876e+00 -8.21530521e-02  6.77055836e-01\n",
      "   -5.55470645e-01 -4.23654556e-01 -4.40105842e-03  2.07923532e-01\n",
      "    2.50403494e-01  7.61161327e-01  9.93776083e-01  7.29656816e-01\n",
      "    3.70116115e-01 -8.87373924e-01  1.35568872e-01 -2.06297245e-02\n",
      "   -9.88412797e-01 -9.32086647e-01 -8.92586648e-01 -1.39172661e+00]\n",
      "  [ 3.22937489e-01  1.15694201e+00 -3.88632208e-01 -4.80813146e-01\n",
      "   -1.43846393e-01 -2.08466262e-01 -8.19829404e-01  8.89398903e-03\n",
      "   -7.62673736e-01  2.68690020e-01 -6.88622177e-01  4.05025035e-01\n",
      "   -3.18208009e-01  5.98631203e-01 -1.37438059e-01  3.89443412e-02\n",
      "   -6.87375903e-01 -2.18121499e-01  1.29151797e+00 -5.68567932e-01\n",
      "    1.28664106e-01 -2.69007742e-01  6.56922996e-01  2.64841139e-01\n",
      "    9.76778746e-01 -4.85973097e-02 -1.16362475e-01  5.21724284e-01\n",
      "    6.76087260e-01 -5.31358957e-01 -4.30985332e-01  4.14370686e-01\n",
      "   -1.25933483e-01  3.60110790e-01 -2.02270940e-01 -6.54428720e-01\n",
      "    3.92889082e-01 -6.41581237e-01  3.73755574e-01 -4.78453428e-01\n",
      "   -8.91560502e-03 -7.30145514e-01  1.06943823e-01 -4.81778115e-01\n",
      "    5.73900044e-01 -2.26610959e-01  6.26965404e-01 -5.12093864e-02\n",
      "   -1.17586128e-01  1.74022615e-01 -1.13930809e+00 -3.48578602e-01\n",
      "    1.05730981e-01  1.61951222e-02  6.45148680e-02  4.29601401e-01\n",
      "   -4.19205397e-01 -2.35481024e+00 -7.56073236e-01  1.36477673e+00\n",
      "    5.56605875e-01 -8.64306092e-01 -4.87572014e-01 -4.11948502e-01]\n",
      "  [-5.08550815e-02  6.09217584e-01 -1.21277317e-01  1.87925786e-01\n",
      "   -7.67475307e-01  4.97258455e-02 -3.89792919e-01 -4.67604846e-02\n",
      "   -7.51564085e-01 -1.28576458e-01 -1.05260742e+00  8.57352197e-01\n",
      "   -6.48415029e-01  2.27037519e-01 -2.75990218e-01  2.01123640e-01\n",
      "   -3.11352938e-01  3.71071212e-02  1.28484845e+00 -1.09835289e-01\n",
      "    6.40651166e-01 -1.08071074e-01 -2.19843596e-01 -2.52144873e-01\n",
      "    7.42294431e-01  3.97514910e-01 -2.42959619e-01  1.95106417e-01\n",
      "    3.96058291e-01 -4.69750941e-01 -7.61762381e-01  3.76158595e-01\n",
      "    1.02325283e-01  4.34571564e-01 -1.30413026e-01 -7.69342005e-01\n",
      "   -4.29649442e-01 -8.30515921e-01  4.65710610e-01 -2.72705674e-01\n",
      "   -1.00737087e-01 -1.08821702e+00  8.84651542e-02  7.67384395e-02\n",
      "    6.56122446e-01 -7.15650141e-01  8.54499102e-01  5.64091265e-01\n",
      "   -2.42188886e-01 -5.12386203e-01 -5.97175539e-01 -5.25158048e-01\n",
      "   -4.75778058e-02  1.66328996e-01  4.02451456e-01  8.97026539e-01\n",
      "   -1.19004436e-01 -1.81182015e+00 -4.32327569e-01  8.64103913e-01\n",
      "    9.47888941e-02 -2.37585858e-01 -6.48985088e-01 -5.18011689e-01]\n",
      "  [ 3.91641736e-01  1.18082404e+00  1.71298832e-01  1.76044419e-01\n",
      "   -5.65419018e-01  3.31184566e-01 -9.01293457e-01 -2.45546028e-01\n",
      "   -1.28267467e+00  5.60354531e-01 -8.74153972e-01 -1.17077559e-01\n",
      "   -1.10708728e-01  1.11927100e-01 -9.37282264e-01  2.76185751e-01\n",
      "   -1.10967755e+00 -2.23332599e-01  1.43034303e+00 -4.12889794e-02\n",
      "    1.42955148e+00 -4.06654328e-01 -9.24991518e-02 -2.46462867e-01\n",
      "    2.77292967e-01  1.06343758e+00  2.84415662e-01 -4.90832925e-02\n",
      "   -1.62719384e-01 -7.06193924e-01 -2.74436980e-01  1.64313924e+00\n",
      "   -3.03564710e-03 -1.18748486e-01 -7.33216345e-01 -9.10473526e-01\n",
      "    4.10369962e-01 -4.78689551e-01  4.35753822e-01 -3.72523330e-02\n",
      "    3.40675533e-01 -6.92292154e-01  3.37906390e-01  4.71738309e-01\n",
      "    1.10765457e+00 -2.36024529e-01  9.99061689e-02  4.43290740e-01\n",
      "   -3.70958298e-01  2.69642562e-01 -5.10657787e-01 -1.81564939e+00\n",
      "   -1.38269797e-01  5.37330031e-01  7.42297113e-01  7.09519207e-01\n",
      "    3.20472062e-01 -2.06822610e+00 -1.89183444e-01  1.54609311e+00\n",
      "    8.97934675e-01 -6.38487399e-01 -8.84617925e-01 -6.70284986e-01]\n",
      "  [ 5.70434153e-01  7.69262910e-01  3.78955081e-02  3.56526613e-01\n",
      "   -4.32762831e-01  8.83497670e-03 -6.26435161e-01  1.90385029e-01\n",
      "   -7.23506987e-01  6.50461555e-01 -7.20059335e-01  2.84894276e-02\n",
      "   -1.32559776e+00  4.63085979e-01  8.46405253e-02 -5.50080240e-01\n",
      "   -1.94088861e-01 -3.10309976e-01  1.50190413e+00 -1.78369433e-01\n",
      "    4.29236710e-01 -7.46883526e-02 -1.83428779e-01  6.17674068e-02\n",
      "    4.83850330e-01  2.69705474e-01  4.55817342e-01  8.58012080e-01\n",
      "    3.26283664e-01  3.40240337e-02 -6.96181357e-01  5.27358472e-01\n",
      "   -1.60800502e-01  7.21068755e-02 -2.57874668e-01 -7.02568829e-01\n",
      "    3.59185964e-01 -5.94897151e-01  2.81399041e-01 -1.39179811e-01\n",
      "    4.17765170e-01 -7.77137339e-01  2.10935175e-01  2.42851581e-02\n",
      "    1.17323466e-01 -5.94869673e-01 -2.92024642e-01 -6.05559528e-01\n",
      "   -2.72122622e-01 -2.61223912e-01 -1.25306499e+00 -8.03906560e-01\n",
      "    3.67123336e-01  2.33532980e-01  5.57249904e-01  1.00388920e+00\n",
      "   -8.29858333e-02 -1.75734067e+00 -9.33253884e-01  1.36784875e+00\n",
      "    2.14099847e-02 -4.45673883e-01 -6.64316475e-01 -3.15133929e-01]]], shape=(2, 5, 64), dtype=float32)\n",
      "attention weights:  tf.Tensor(\n",
      "[[[[0.15221938 0.05177133 0.02585601 0.41585627 0.354297  ]\n",
      "   [0.05207327 0.46279007 0.08916884 0.2385493  0.15741852]\n",
      "   [0.3217905  0.06832273 0.14319512 0.03327562 0.43341613]\n",
      "   [0.18417172 0.18952994 0.0998829  0.45516694 0.07124847]\n",
      "   [0.05886697 0.01476738 0.01180254 0.3837081  0.530855  ]]\n",
      "\n",
      "  [[0.5059105  0.09149244 0.16740717 0.1048702  0.1303196 ]\n",
      "   [0.14854051 0.04231461 0.12098154 0.20544451 0.4827189 ]\n",
      "   [0.13184081 0.47112045 0.08528504 0.19853298 0.1132208 ]\n",
      "   [0.16407207 0.1899966  0.2692475  0.18844391 0.18823992]\n",
      "   [0.04772029 0.2303766  0.2582167  0.2878263  0.17586012]]\n",
      "\n",
      "  [[0.18525137 0.15022206 0.10891606 0.02441175 0.53119886]\n",
      "   [0.29866382 0.1083395  0.08746909 0.19735506 0.30817252]\n",
      "   [0.18466097 0.32292962 0.09992126 0.124667   0.267821  ]\n",
      "   [0.15390743 0.31656525 0.32778648 0.12192113 0.07981961]\n",
      "   [0.06614283 0.23783329 0.4673656  0.22048315 0.00817503]]\n",
      "\n",
      "  [[0.12146451 0.13052596 0.26000783 0.12323193 0.36476985]\n",
      "   [0.03802202 0.04490394 0.4704667  0.38603967 0.06056757]\n",
      "   [0.280107   0.12520376 0.35897866 0.12247779 0.11323281]\n",
      "   [0.1134997  0.11556907 0.16136551 0.054431   0.5551346 ]\n",
      "   [0.14738378 0.171007   0.3728843  0.23887156 0.06985337]]\n",
      "\n",
      "  [[0.65671575 0.03713403 0.24145739 0.0436856  0.02100724]\n",
      "   [0.7838419  0.06427912 0.06037948 0.01323613 0.07826333]\n",
      "   [0.22520173 0.1635715  0.13120723 0.19942246 0.2805971 ]\n",
      "   [0.3100358  0.15113631 0.32920676 0.15562147 0.05399976]\n",
      "   [0.16240986 0.24750559 0.07581004 0.01780013 0.49647447]]\n",
      "\n",
      "  [[0.09352852 0.20687573 0.22658478 0.0454763  0.42753476]\n",
      "   [0.49162877 0.16696855 0.03235211 0.28295183 0.02609866]\n",
      "   [0.05686639 0.05332079 0.50742567 0.31585038 0.06653685]\n",
      "   [0.17463171 0.11256234 0.1207009  0.3862536  0.20585144]\n",
      "   [0.51464725 0.09708367 0.08743475 0.25981322 0.04102112]]\n",
      "\n",
      "  [[0.04053267 0.0372124  0.15946153 0.09720474 0.66558874]\n",
      "   [0.13737111 0.3761472  0.07846602 0.26026672 0.14774896]\n",
      "   [0.18977027 0.0521782  0.2982237  0.37147895 0.08834883]\n",
      "   [0.02904309 0.04396231 0.11240763 0.32894614 0.48564085]\n",
      "   [0.08647159 0.02142065 0.40872023 0.27239814 0.21098933]]\n",
      "\n",
      "  [[0.08438414 0.53973234 0.03996991 0.128812   0.20710164]\n",
      "   [0.23727046 0.03941068 0.15652326 0.20244406 0.36435157]\n",
      "   [0.19899626 0.2217996  0.2321246  0.11205312 0.23502633]\n",
      "   [0.14836958 0.04457689 0.02527446 0.4828443  0.29893488]\n",
      "   [0.08597322 0.04494676 0.3376253  0.4455995  0.08585514]]]\n",
      "\n",
      "\n",
      " [[[0.69219637 0.06794678 0.12634377 0.04101139 0.07250173]\n",
      "   [0.04275519 0.00514617 0.02873882 0.05540037 0.86795944]\n",
      "   [0.1246612  0.11464754 0.4388081  0.05435784 0.26752526]\n",
      "   [0.02994662 0.03341319 0.61647743 0.07451503 0.24564779]\n",
      "   [0.10525333 0.31471816 0.09198675 0.34642562 0.14161614]]\n",
      "\n",
      "  [[0.6706772  0.15772505 0.09989227 0.03928357 0.03242184]\n",
      "   [0.11663962 0.05013167 0.2906068  0.43926552 0.10335638]\n",
      "   [0.24206485 0.14315635 0.44928306 0.01063546 0.15486027]\n",
      "   [0.04982776 0.11436122 0.19514312 0.16222297 0.47844484]\n",
      "   [0.3841336  0.1508618  0.21423149 0.19537    0.05540306]]\n",
      "\n",
      "  [[0.02461792 0.0277035  0.9209105  0.01091969 0.01584837]\n",
      "   [0.22934991 0.3515432  0.03529944 0.2753977  0.10840978]\n",
      "   [0.127771   0.1435736  0.21776824 0.2223626  0.28852454]\n",
      "   [0.02153433 0.18895613 0.00282846 0.4112014  0.37547967]\n",
      "   [0.13300343 0.13437384 0.10087066 0.45756516 0.17418693]]\n",
      "\n",
      "  [[0.09813185 0.11506858 0.61983705 0.15050428 0.01645827]\n",
      "   [0.03420872 0.64815843 0.04319016 0.03526612 0.23917654]\n",
      "   [0.03709337 0.06258535 0.07316083 0.7247979  0.10236255]\n",
      "   [0.21003737 0.08966175 0.3454715  0.19597703 0.15885232]\n",
      "   [0.48499596 0.16816153 0.21718907 0.07370672 0.05594669]]\n",
      "\n",
      "  [[0.29272005 0.22132294 0.2818883  0.06762506 0.13644359]\n",
      "   [0.02129205 0.1343947  0.08039724 0.6958787  0.0680373 ]\n",
      "   [0.05113954 0.2343722  0.04990405 0.2754144  0.38916972]\n",
      "   [0.04039518 0.04838331 0.14819504 0.08125249 0.6817739 ]\n",
      "   [0.10623875 0.548558   0.13165179 0.10582279 0.10772869]]\n",
      "\n",
      "  [[0.0584116  0.3766115  0.12017739 0.35348344 0.09131598]\n",
      "   [0.05363834 0.2980269  0.03229064 0.569204   0.04684018]\n",
      "   [0.20618781 0.17552535 0.08325277 0.15904917 0.37598485]\n",
      "   [0.00175138 0.94815344 0.00928715 0.02849038 0.01231765]\n",
      "   [0.11088113 0.61307466 0.13481624 0.0464099  0.09481803]]\n",
      "\n",
      "  [[0.11285376 0.2588337  0.21961448 0.35311225 0.05558581]\n",
      "   [0.19760886 0.12174441 0.2679147  0.1296548  0.2830772 ]\n",
      "   [0.22077623 0.44360405 0.05798673 0.05578015 0.2218528 ]\n",
      "   [0.09267084 0.13179807 0.20115419 0.39348662 0.18089013]\n",
      "   [0.20059612 0.14790563 0.22862597 0.21599233 0.20687987]]\n",
      "\n",
      "  [[0.06681912 0.11099271 0.1531767  0.2978718  0.37113976]\n",
      "   [0.2727471  0.15938845 0.373203   0.09569213 0.09896931]\n",
      "   [0.3287191  0.03513727 0.12555525 0.0461414  0.46444702]\n",
      "   [0.14326707 0.13962904 0.15522155 0.16312446 0.39875793]\n",
      "   [0.22661294 0.32790896 0.04508399 0.20647594 0.19391808]]]], shape=(2, 8, 5, 5), dtype=float32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"context vector: \",context_vector) , print(\"attention weights: \",attention_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
